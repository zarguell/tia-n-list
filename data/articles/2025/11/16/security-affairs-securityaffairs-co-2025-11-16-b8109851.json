{
  "id": "security-affairs-securityaffairs-co-2025-11-16-b8109851",
  "source_id": "security-affairs-securityaffairs-co",
  "guid": "https://securityaffairs.com/?p=184666",
  "title": "Anthropic: China-backed hackers launch first large-scale autonomous AI cyberattack",
  "url": "https://securityaffairs.com/184666/hacking/anthropic-china-backed-hackers-launch-first-large-scale-autonomous-ai-cyberattack.html",
  "published_at": "2025-11-16T07:56:46+00:00",
  "fetched_at": "2025-11-16T11:18:37.707545+00:00Z",
  "status": "fetched",
  "content": {
    "raw": "China-linked actors used Anthropic’s AI to automate and run cyberattacks in a sophisticated 2025 espionage campaign using advanced agentic tools. China-linked threat actors used Anthropic’s AI to automate and execute cyberattacks in a highly sophisticated espionage campaign in September 2025. The cyber spies leveraged advanced “agentic” capabilities rather than using AI only for guidance. Attackers abused AI’s agentic capabilities to execute cyberattacks autonomously. According to the experts, this represents an unprecedented shift from AI as advisor to AI as operator. A Chinese state-sponsored group used Claude Code to target about 30 global organizations, succeeding in a few cases across tech, finance, chemicals, and government. It’s likely the first large-scale attack with minimal human involvement. &#8220;In mid-September 2025, we detected suspicious activity that later investigation determined to be a highly sophisticated espionage campaign.&#8221; reads the report published by Anthropic. &#8220;After detection, accounts were banned, victims notified, and authorities engaged. The case highlights rising risks from autonomous AI agents and the need for stronger detection and defensive measures.&#8221; The attack exploited three newly matured AI capabilities. First, greater intelligence let models follow complex instructions and use advanced skills like coding for malicious tasks. Second, increased agency enabled AI agents to act autonomously, chaining actions and making decisions with minimal human input. Third, broad tool access, via standards like MCP, allowed models to use web search, data retrieval, password crackers, and network scanners. Each attack phase relied on this combination of intelligence, autonomy, and tool integration. The cyberspies selected targets and built an autonomous attack framework using Claude Code. After jailbreaking Claude by disguising tasks as benign and framing the activity as defensive testing, they launched Phase 2. Claude rapidly mapped systems, identified high-value databases, and reported findings. It then researched and wrote exploits, harvested credentials, created backdoors, and exfiltrated data with minimal human oversight. Claude even documented the operation. Overall, the AI performed 80–90% of the campaign, executing thousands of requests at speeds impossible for humans, though occasional hallucinations limited full autonomy. The attack marks an escalation from past “vibe hacking,” with far less human involvement and large-scale AI-driven operations. Yet the same capabilities enabling misuse make AI vital for defense: Claude was used to analyze the investigation’s data. Cybersecurity is shifting; teams should adopt AI for SOC work, detection, and response, while improving safeguards, threat sharing, and monitoring. &#8220;The barriers to performing sophisticated cyberattacks have dropped substantially—and we predict that they’ll continue to do so. With the correct setup, threat actors can now use agentic AI systems for extended periods to do the work of entire teams of experienced hackers: analyzing target systems, producing exploit code, and scanning vast datasets of stolen information more efficiently than any human operator.&#8221; concludes the report. &#8220;Less experienced and resourced groups can now potentially perform large-scale attacks of this nature.&#8221; Many experts are skeptical about Anthropic&#8217;s report, one of them is the famous Kevin Beaumont, below is the statement he wrote on LinkedIn: &#8220;I&#8217;m a really weird stage in my career &#8211; a bad point &#8211; where I&#8217;m having to go to prominent industry leaders and be like &#8216;you realise that article you just shared about 90% of ransomware being from GenAI isn&#8217;t real&#8217; constantly.100% think a load of these people are thinking I don&#8217;t know what I&#8217;m on about, because 1000 other industry leaders have told them about GenAI ransomware.It&#8217;s really interesting to watch though as basically China has played a blinder, Chinese whisper panic basically.Definitely interesting as you&#8217;ve got really big, trusted orgs putting out absolute nonsense &#8211; and really big industry figureheads repeating it, and surveys with CISOs saying they&#8217;re seeing 70% of ransomware being AI (spoiler: they aren&#8217;t, they likely haven&#8217;t dealt with a single ransomware incident themselves).A lot of it is about retaining CISO budgets and making sales.But there&#8217;s also a lot of people who don&#8217;t realise what is happening, and it ain&#8217;t based on evidence. Embarrassing for me.If you&#8217;re wondering what any of this has to do with China by the way: China knows the west are obsessed with AI threats. It&#8217;s a really easy way to distract entire countries.There&#8217;s a reason why &#8216;oh no, threat actor has made some completely shit GenAI malware using ChatGPT&#8217; things keep coming along, rather than in locally hosted AI tools.They have a laser pointer, and y&#8217;all are their cats, while they take yer cat food away. They want to be seen.If you don&#8217;t believe me btw, the stuff generated in that &#8220;blockbuster&#8221; WSJ report had Chinese .WAV file songs embedded in it, and jokes. And it didn&#8217;t even run properly. And everybody ran off a cliff with it in a panic, taking actions without any info.Personally I think hats off as they&#8217;re running rings around everybody. The best way to make sure orgs don&#8217;t do real security foundations is via this strategy.&#8221; Follow me on Twitter:&nbsp;@securityaffairs&nbsp;and&nbsp;Facebook&nbsp;and&nbsp;Mastodon Pierluigi&nbsp;Paganini (SecurityAffairs&nbsp;–&nbsp;hacking,&nbsp;Anthropic)",
    "full": "",
    "processed": ""
  },
  "analysis": {
    "score": null,
    "relevance_score": null,
    "threat_category": null,
    "summary": null,
    "key_entities": [],
    "ttps": []
  },
  "content_source": "rss",
  "content_fetch_method": null,
  "processing_metadata": {}
}