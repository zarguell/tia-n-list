{
  "id": "qualys-security-blog-2025-11-20-7423f956",
  "source_id": "qualys-security-blog",
  "guid": "https://blog.qualys.com/?p=39155",
  "title": "GenAI: Harness the Power, Eliminate the Risk — A Practical Playbook for Securing AI from Day One",
  "url": "https://blog.qualys.com/category/product-tech",
  "published_at": "2025-11-20T21:36:10+00:00",
  "fetched_at": "2025-11-21T11:18:56.592469+00:00Z",
  "status": "fetched",
  "content": {
    "raw": "Enterprises everywhere are racing to leverage AI to gain sharper insights, automate workflows, and deliver richer customer experiences. Based on an assessment conducted by Bain &amp; Company, generative AI adoption is soaring, with 95% of US companies using it, up 12 percentage points in just a year. Similarly, an EY survey found that 48% of tech executives are already adopting or fully deploying agentic AI. But as they say, with great power comes a greater attack surface — one that learns, executes, and sometimes misbehaves. As AI adoption accelerates, so do the risks. For example, nearly 99% of AI-related vulnerabilities are tied to API flaws and 89% of AI-powered APIs lack secure authentication. The AI boom is fueled by record-high enterprise adoption, and the rapid rise of agentic AI has collided with an explosion of operational security and compliance risk. As AI capabilities become deeply embedded across cloud platforms, applications, DevOps pipelines, and even the tools that secure them, organizations now face an attack surface that not only expands but thinks, adapts, and occasionally acts out. This is why forward-leaning security teams are combining Qualys TotalAI with TotalCloud and TotalAppSec to unify AI safety testing, AI vulnerability detection, cloud and container posture security, application security, API security, and risk prioritization into a single, contextual picture. With accelerated AI adoption, only a unified approach can help organizations harness the capabilities while eliminating the dangers. Unlock the potential of Qualys TotalAI. Find out More Threat Landscape Recent industry headlines reveal just how risky the AI attack surface can be for organizations: NYC’s AI Chatbot encouraged business owners to break the law A major international airline had to pay damages for misinformation provided by its chatbot The Chicago Sun-Times and the Philadelphia Inquirer got some bad press for mistakenly publishing a fake summer reading list ChatGPT, when asked to find legal precedent, hallucinated court cases These incidents show how easily AI systems can expose organizations to legal safety compliance and reputational damage through harmful, illegal, misleading, or fabricated outputs. As enterprises deploy AI faster across cloud and application ecosystems, the potential blast radius widens dramatically. This can also lead to potential lawsuits, regulatory scrutiny, and public backlash. In order to understand the issue holistically, let’s look at the Generative and Agentic AI more closely. Generative AI workflow and risk lifecycle GenAI is a subfield of AI that uses generative models to produce text, code, audio, video, or other forms of data. GenAI workflow involves the following steps, which introduce the associated risks. Data collection and curation: Data that is collected and curated may be malicious, poisoned, or sensitive. Training and fine-tuning: The basemodel may be vulnerable.Malicious, poisoned, or sensitive data may create problems in the training or fine-tuning phase. Evaluation and testing: Evaluation tools may be compromised. The model may inadvertently leak sensitive data. Models may be vulnerable to extraction and integrity attacks. Deployment, Inference: The deployment stack may be vulnerable. The model may be vulnerable to DoS attacks. User Interaction: User is untrusted, and their prompts may be unsafe. Feedback and iteration: User feedback may be malicious, compromised, poisoned, or sensitive. Each of these stages intersects with cloud environments, repositories, pipelines, and external systems, making integrated cloud security visibility essential. This is where combining TotalAI with TotalCloud gives organizations an end-to-end view across both the AI and cloud workflow. Fig 1 Agentic AI workflow and risk lifecycle AI Agent workflow Agent input = User input + contextual data The model reasons about the agent’s goals and develops a plan The agent interacts with external systems or resources via tools or actions. (The AI agent, as an MCP client, queries the MCP server for available tools and data) Memory retains context across interactions, stores learned user preferences The agent’s output is displayed within the user’s application interface Risks Involved Untrusted user input or external content may lead to prompt injection attacks Iterative planning may cause logic errors, intent drift, or malicious hijacking Uncontrolled tool access can enable harmful actions if planning is compromised, or tools may be rogue, insecure, or leak sensitive data. Malicious data stored in memory can become a vector for persistent attacks Unsanitized agent output may cause XSS or data exfiltration vulnerabilities. As you can see, there are many points of security failure in the AI workflows described above. Even if you start with a safe base model, you may introduce vulnerabilities during fine-tuning, training, evaluation, deployment, and inference. Also, most of the weaknesses become visible when users start interacting with the model or the agent. That is why AI risks must not be assessed in isolation. When agents act across cloud resources, the security stakes increase. Pairing TotalAI with TotalCloud enables detection of risky agent behaviors, insecure tool chains, and unsafe agent actions, within cloud and container environments. Why AI Risks Cannot Be Assessed in Isolation AI risks must never be evaluated in isolation because modern AI systems operate across interconnected application infrastructure, identity, and cloud stacks. Even a well-aligned LLM can become high risk if deployed on misconfigured cloud infrastructure, insecure APIs, or vulnerable dependent services. Toxic combinations across data pipelines, orchestration layers, and agentic actions magnify the overall risk posture. Together, toxic combinations may multiply risks. For example, even if an LLM is well-aligned and protected against prompt exploitation, it may still be deployed on vulnerable infrastructure, may have insecure APIs, or misconfigured data stores, making it possible for attackers to steal models, training data, or system secrets. Similarly, AI threats are not limited to inference endpoints—AI is increasingly embedded across applications, APIs, agents, data pipelines, and orchestration layers. Understanding AI exposure requires correlating these components to accurately assess the blast radius of a compromise and determine how an exploited weakness in one layer can cascade into system-wide business impact. Meet Qualys TotalAI — powering AI risk management in Qualys Enterprise TruRisk Platform A holistic risk assessment must therefore consider not only model behavior and prompt safety, but also the full stack that enables the AI system to operate. This includes software dependencies, identity and access controls, network posture, security controls, and the sensitivity and governance of underlying data. That is why Qualys TotalAI is integrated into the Qualys Enterprise TruRisk Platform—to bring AI security into the same risk model used for applications, infrastructure, and cloud services and setting organizations up to implement their own Risk Operations Center (ROC). By correlating AI risks with the surrounding environment, organizations can prioritize remediation more intelligently, understand real operational exposure, and manage AI adoption with confidence and measurable risk reduction. When paired with Qualys TotalCloud and TotalAppSec, teams gain correlated context across cloud misconfigurations, identity exposures, AI and API vulnerabilities, and model safety issues, all prioritized through TruRisk. TotalAI powers AI risk management capabilities of the Qualys platform, with unified visibility, risk assessment, and response across: LLMs and model artifacts AI workloads and MCP servers AI agents (on the roadmap) AI software packages, frameworks, and GPUs AI-specific vulnerabilities (1000+ detections) Unlike other solutions which require new sensors and deployments, Qualys customers get AI Scanning out of the box with their existing Cloud Agents and Scanners &#8211; enabling instant LLM discovery and scanning. When combined with TotalCloud’s container cloud and serverless visibility, organizations get a complete AI-to-cloud risk picture in a single platform. Key TotalAI capabilities Fig 3 1) Full inventory of AI assets Automatically discover models, AI workloads, MCP Servers, AI Software Packages, GPUs, and AI infrastructures across multi-cloud including AWS Bedrock/Sagemaker, Azure Open AI, Google Vertex, Hugging Face, and any on-premises model. 2) Security + Safety testing of models TotalAI assesses models for bias and safety (toxicity, harassment, hate speech, discriminatory behavior), factual inconsistencies, illegal activities, security vulnerabilities (such as prompt injection, jailbreak vectors) outlined in “OWASP TOP 10 for LLM” to check if models can be coaxed into leaking data or giving risky, illegal, biased, problematic responses. 3) AI-specific vulnerability detection TotalAI includes an AI-tailored vulnerability catalog (1,000+ AI-specific vulnerability detections) that is correlated with threat intelligence to produce meaningful remediation priorities via TruRisk. 4) Unified reporting &amp; executive-ready narratives Generate categorized, context-rich LLM security reports for stakeholders — making it easier to summarize risks, remediation status, and compliance posture to executives and auditors. TotalAI findings map to OWASP Top 10 for LLMs, MITRE ATLAS (threat techniques for AI), and compliance requirements (GDPR, PCI, and EU AI Act). This alignment helps security and compliance teams translate technical issues into regulatory and business risk. Practical checklist to be ROC-ready Inventory: Run an auto-discovery across cloud and on-prem to enumerate models, agents, and GPUs. Baseline: Run AI-specific vulnerability scans and model safety tests. Prioritize: Use TruRisk or an equivalent to map technical findings to business impact. Remediate: Patch infrastructure, rotate keys, fix prompt design, revoke access to exposed models. Monitor: Continuously test for prompt injection, data leakage, and anomalous model behavior. Report: Produce regular executive-ready reports mapped to relevant regulatory requirements. Govern: Create policies for acceptable use of AI/LLM technologies and data hygiene. With TotalAI, TotalAppSec, and TotalCloud working together, organizations can automate nearly all of these steps to correlate AI and cloud risks for more accurate prioritization and faster remediation. Implementation tips Don’t rely on manual inventory — agentic AI and third-party models proliferate quickly. Treat model artifacts as crown jewels — back them up, control access, and ensure provenance. Test for both safety and security — safety (bias/toxicity) and security (injection, exfiltration) are distinct but overlapping concerns. Map remediation to business context — fix high-business-impact risks first, not just high-severity CVEs without context. Prepare for regulation — the EU AI Act and similar rules will expect documented risk management for high-risk models. Integrating TotalCloud ensures these controls extend into the cloud infrastructure where most AI systems ultimately operate. Secure innovation is possible — but it’s active work Generative AI unlocks enormous value but creates new attack surfaces that require an evolution of security practice. Establish a Risk Operation Center (ROC), get complete visibility of AI assets, perform both safety and security testing, correlate vulnerabilities to real threats, and make remediation and reporting operational. Qualys TotalAI, combined with Qualys TotalCloud, brings full-spectrum AI LLM cloud and container risk into a single unified platform to deliver correlated insights, prioritized remediation, and continuous monitoring, powered by the TruRisk engine. With this integrated approach, organizations can accelerate AI adoption confidently and securely from day one. Get Started with Qualys Solutions Today. Try Today Contributors Balaji Venkatesan, Senior Director of Engineering, Data Platform, Qualys",
    "full": "",
    "processed": ""
  },
  "analysis": {
    "score": null,
    "relevance_score": null,
    "threat_category": null,
    "summary": null,
    "key_entities": [],
    "ttps": []
  },
  "content_source": "rss",
  "content_fetch_method": null,
  "processing_metadata": {}
}