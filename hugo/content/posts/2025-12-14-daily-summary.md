---
title: AI GitHub supply chain attacks ðŸ¤–, PyStoreRAT backdoor ðŸŽ¯, developer targeting ðŸ’»
date: 2025-12-14
tags: ["supply chain attack","github","ai-generated content","pystorerat","backdoor","developers","researchers","llm abuse","code security"]
categories: ["Threat Intelligence"]
author: Tia N. List
summary: AI-driven GitHub supply chain attacks using AI-generated repositories are actively targeting researchers and developers with PyStoreRAT backdoor. The campaign leverages reactivated dormant accounts and LLM-generated professional code to enable remote compromise and persistent data theft through malicious repository downloads.
---

# Daily Threat Intel Digest - 2025-12-14

## ðŸ”´ Critical Threats & Active Exploitation

**[NEW] AI-Driven GitHub Supply Chain Attack Delivers PyStoreRAT Backdoor**
A sophisticated supply chain campaign is actively targeting researchers and developers by distributing a previously undocumented backdoor through convincing, AI-generated GitHub repositories [Researchers and Developers Targeted in AI-Driven GitHub Supply Chain Attack](https://gbhackers.com/researchers-targeted-in-ai-driven-github-supply-chain-attack/). Morphisec Threat Labs reports the attackers reactivate dormant GitHub accounts to add legitimacy to these malicious projects, which then deliver PyStoreRAT [Researchers and Developers Targeted in AI-Driven GitHub Supply Chain Attack](https://gbhackers.com/researchers-targeted-in-ai-driven-github-supply-chain-attack/). The use of large language models to craft professional-looking code and documentation lowers the barrier for creating credible lures, putting any developer who clones or downloads from untrusted repositories at direct risk of remote compromise and persistent data theft. Security teams should advise development staff to scrutinize repository history, contributor activity, and code contents, especially from accounts that have been inactive for long periods.