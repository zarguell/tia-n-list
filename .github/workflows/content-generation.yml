name: Daily Content Generation

on:
  schedule:
    # Run daily at 6:00 AM EST (11:00 AM UTC)
    - cron: '0 11 * * *'
  workflow_dispatch: # Allow manual triggering

jobs:
  generate-content:
    runs-on: ubuntu-latest
    permissions:
      contents: write

    steps:
    - name: Harden the runner (Audit all outbound calls)
      uses: step-security/harden-runner@df199fb7be9f65074067a9eb93f12bb4c5547cf2 # v2.13.3
      with:
        egress-policy: audit

    - name: Checkout repository
      uses: actions/checkout@8e8c483db84b4bee98b60c0593521ed34d9990e8 # v6.0.1
      with:
        token: ${{ secrets.GITHUB_TOKEN }}
        submodules: 'recursive'  # Initialize Hugo theme submodule

    - name: Set up Python 3.13
      uses: actions/setup-python@83679a892e2d95755f2dac6acb0bfd1e9ac5d548 # v6.1.0
      with:
        python-version: '3.13'

    - name: Cache pip dependencies
      uses: actions/cache@0057852bfaa89a56745cba8c7296529d2fc39830 # v4.3.0
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-

    - name: Install Python dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt

    - name: Create data directory
      run: |
        mkdir -p data

    - name: Run Unified RSS Feed Ingestion
      env:
        GEMINI_API_KEY: ${{ secrets.GEMINI_API_KEY }}
        OPENROUTER_API_KEY: ${{ secrets.OPENROUTER_API_KEY }}
        OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
        LLM_PROVIDER: ${{ vars.LLM_PROVIDER || 'openrouter' }}
        OPENROUTER_FILTERING_MODEL: ${{ vars.OPENROUTER_FILTERING_MODEL || 'meta-llama/llama-3.3-8b-instruct:free' }}
        OPENROUTER_ANALYSIS_MODEL: ${{ vars.OPENROUTER_ANALYSIS_MODEL || 'openai/gpt-oss-20b:free' }}
        STORAGE_PROVIDER: ${{ vars.STORAGE_PROVIDER || 'json' }}
      run: |
        echo "ğŸ”„ Starting unified RSS feed ingestion..."
        PYTHONPATH=. python -m src.unified_ingestion
        echo "âœ… RSS ingestion completed"
        echo "ğŸ“Š System statistics:"
        PYTHONPATH=. python -c "from src.storage_registry import get_default_storage_provider; from datetime import date; storage = get_default_storage_provider(); articles = storage.get_articles_by_date_range(start_date=date.today(), end_date=date.today()); print(f'Articles: {len(articles)}')"

    - name: Enhance Article Content
      env:
        GEMINI_API_KEY: ${{ secrets.GEMINI_API_KEY }}
        OPENROUTER_API_KEY: ${{ secrets.OPENROUTER_API_KEY }}
        OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
        LLM_PROVIDER: ${{ vars.LLM_PROVIDER || 'openrouter' }}
        OPENROUTER_FILTERING_MODEL: ${{ vars.OPENROUTER_FILTERING_MODEL || 'meta-llama/llama-3.3-8b-instruct:free' }}
        OPENROUTER_ANALYSIS_MODEL: ${{ vars.OPENROUTER_ANALYSIS_MODEL || 'openai/gpt-oss-20b:free' }}
      run: |
        echo "ğŸ“° Enhancing article content with timeout protection..."
        echo "ğŸ”’ Using enhanced script with per-article and overall timeouts"
        PYTHONPATH=. python scripts/enhance_content_with_timeout.py

    - name: Run Unified LLM Processing
      env:
        GEMINI_API_KEY: ${{ secrets.GEMINI_API_KEY }}
        OPENROUTER_API_KEY: ${{ secrets.OPENROUTER_API_KEY }}
        OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
        LLM_PROVIDER: ${{ vars.LLM_PROVIDER || 'openrouter' }}
        OPENROUTER_FILTERING_MODEL: ${{ vars.OPENROUTER_FILTERING_MODEL || 'meta-llama/llama-3.3-8b-instruct:free' }}
        OPENROUTER_ANALYSIS_MODEL: ${{ vars.OPENROUTER_ANALYSIS_MODEL || 'openai/gpt-oss-20b:free' }}
        STORAGE_PROVIDER: ${{ vars.STORAGE_PROVIDER || 'json' }}
      run: |
        echo "ğŸ§  Starting unified LLM processing..."
        echo "Using LLM provider: ${LLM_PROVIDER:-openrouter}"
        echo "ğŸ“Š Processing articles with AI analysis and IOC extraction"
        PYTHONPATH=. python -m src.unified_processing

    - name: Generate JSON Blog Post
      env:
        GEMINI_API_KEY: ${{ secrets.GEMINI_API_KEY }}
        OPENROUTER_API_KEY: ${{ secrets.OPENROUTER_API_KEY }}
        OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
        LLM_PROVIDER: ${{ vars.LLM_PROVIDER || 'openrouter' }}
        OPENROUTER_FILTERING_MODEL: ${{ vars.OPENROUTER_FILTERING_MODEL || 'meta-llama/llama-3.3-8b-instruct:free' }}
        OPENROUTER_ANALYSIS_MODEL: ${{ vars.OPENROUTER_ANALYSIS_MODEL || 'openai/gpt-oss-20b:free' }}
        USE_OPTIMIZED_PROMPT: ${{ vars.USE_OPTIMIZED_PROMPT || 'true' }}
        USE_DYNAMIC_TITLES: ${{ vars.USE_DYNAMIC_TITLES || 'true' }}
        USE_DYNAMIC_TAGS: ${{ vars.USE_DYNAMIC_TAGS || 'true' }}
        USE_ENHANCED_PROMPTS: ${{ vars.USE_ENHANCED_PROMPTS || 'true' }}
        USE_TWO_TIER_ANALYSIS: ${{ vars.USE_TWO_TIER_ANALYSIS || 'true' }}
        LLM_MAX_TOKENS_BLOG: ${{ vars.LLM_MAX_TOKENS_BLOG || '10000' }}
      run: |
        echo "ğŸš€ Generating enhanced blog post with dynamic content..."
        echo "Using LLM provider: ${LLM_PROVIDER:-openrouter}"
        echo "ğŸš€ Prompt optimization: ${USE_OPTIMIZED_PROMPT:-true} ($(if [ "${USE_OPTIMIZED_PROMPT:-true}" = "true" ]; then echo "OPTIMIZED (16.5% fewer tokens)"; else echo "COMPREHENSIVE (maximum detail)"; fi))"
        echo "ğŸ¯ Dynamic titles: ${USE_DYNAMIC_TITLES:-true} ($(if [ "${USE_DYNAMIC_TITLES:-true}" = "true" ]; then echo "ENABLED (engaging, SEO-optimized)"; else echo "DISABLED (static titles)"; fi))"
        echo "ğŸ·ï¸  Dynamic tags: ${USE_DYNAMIC_TAGS:-true} ($(if [ "${USE_DYNAMIC_TAGS:-true}" = "true" ]; then echo "ENABLED (smart extraction)"; else echo "DISABLED (basic tags)"; fi))"
        echo "ğŸ“ Enterprise-grade prompts: ${USE_ENHANCED_PROMPTS:-true} ($(if [ "${USE_ENHANCED_PROMPTS:-true}" = "true" ]; then echo "ENABLED (confidence assessments, ATT&CK, business impact)"; else echo "DISABLED (standard prompts)"; fi))"
        echo "ğŸ”„ Two-tier analysis: ${USE_TWO_TIER_ANALYSIS:-true} ($(if [ "${USE_TWO_TIER_ANALYSIS:-true}" = "true" ]; then echo "ENABLED (focused synthesis + enterprise enhancement)"; else echo "DISABLED (single-tier enhanced)"; fi))"
        echo "ğŸ“ Blog token limit: ${LLM_MAX_TOKENS_BLOG:-10000} ($(if [ "${LLM_MAX_TOKENS_BLOG:-10000}" = "10000" ]; then echo "MAXIMUM (comprehensive briefings)"; else echo "CUSTOM ($LLM_MAX_TOKENS_BLOG tokens)"; fi))"
        PYTHONPATH=. python scripts/generate_blog_json.py

    - name: Check for generated content
      id: check-content
      run: |
        echo "ğŸ” Checking for generated content..."

        # Check JSON data
        JSON_CHANGES=false
        if [ -n "$(git status --porcelain data/)" ]; then
          JSON_CHANGES=true
          echo "âœ… Found JSON data changes"
        fi

        # Check blog posts
        BLOG_CHANGES=false
        if [ -n "$(git status --porcelain hugo/content/posts/)" ]; then
          BLOG_CHANGES=true
          echo "âœ… Found blog post changes"
        fi

        # Set outputs for debugging
        echo "json-changes=$JSON_CHANGES" >> $GITHUB_OUTPUT
        echo "blog-changes=$BLOG_CHANGES" >> $GITHUB_OUTPUT

        if [ "$JSON_CHANGES" = "true" ] || [ "$BLOG_CHANGES" = "true" ]; then
          echo "has-changes=true" >> $GITHUB_OUTPUT
          echo "ğŸ‰ Found new content to commit"
        else
          echo "has-changes=false" >> $GITHUB_OUTPUT
          echo "â„¹ï¸  No new content generated"
        fi

    - name: Commit and push generated content
      if: steps.check-content.outputs.has-changes == 'true'
      run: |
        echo "ğŸ“ Committing generated content..."

        # Configure git
        git config --local user.email "action@github.com"
        git config --local user.name "GitHub Action"

        # Show what we're committing
        echo "ğŸ“Š Git status:"
        git status

        echo "ğŸ“‹ Changes to be committed:"
        git diff --name-only

        # Stage only source content (NOT Hugo build output)
        git add data/
        git add hugo/content/posts/

        # Verify staged changes
        echo "âœ… Staged changes:"
        git diff --staged --name-only

        # Commit with detailed message
        DATE=$(date +'%Y-%m-%d')
        TIME=$(date +'%H:%M:%S')

        git commit -m "ğŸ›¡ï¸ Daily Threat Intelligence Briefing - $DATE

        ğŸ“Š Content Generation Summary:
        â€¢ JSON Data: ${{ steps.check-content.outputs.json-changes }}
        â€¢ Blog Posts: ${{ steps.check-content.outputs.blog-changes }}
        â€¢ Generated: $TIME UTC

        ğŸ¤– Generated with [Claude Code](https://claude.com/claude-code)

        Co-Authored-By: Claude <noreply@anthropic.com>"

        echo "ğŸš€ Pushing changes to repository..."
        git push

    - name: Content Generation Summary
      run: |
        echo "## ğŸ›¡ï¸ Content Generation Summary" >> $GITHUB_STEP_SUMMARY
        echo "**Date:** $(date +'%Y-%m-%d %H:%M:%S UTC')" >> $GITHUB_STEP_SUMMARY
        echo "**Status:** ${{ steps.check-content.outputs.has-changes == 'true' && 'âœ… Content Generated' || 'â„¹ï¸ No New Content' }}" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY

        echo "### ğŸ“Š Generation Results:" >> $GITHUB_STEP_SUMMARY
        echo "- **JSON Data:** ${{ steps.check-content.outputs.json-changes == 'true' && 'âœ… Updated' || 'â„¹ï¸ No changes' }}" >> $GITHUB_STEP_SUMMARY
        echo "- **Blog Posts:** ${{ steps.check-content.outputs.blog-changes == 'true' && 'âœ… Generated' || 'â„¹ï¸ No changes' }}" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY

        # Check JSON storage status
        if [ -d "data" ]; then
          ARTICLE_COUNT=$(find data/articles -name "*.json" -type f 2>/dev/null | wc -l)
          PROCESSED_COUNT=$(find data/articles -name "*.json" -type f -exec grep -l '"status": "processed"' {} \; 2>/dev/null | wc -l)
          echo "### ğŸ“ˆ System Statistics:" >> $GITHUB_STEP_SUMMARY
          echo "- **Total Articles:** $ARTICLE_COUNT" >> $GITHUB_STEP_SUMMARY
          echo "- **Processed Articles:** $PROCESSED_COUNT" >> $GITHUB_STEP_SUMMARY
          echo "- **Processing Rate:** $(echo "scale=1; $PROCESSED_COUNT * 100 / $ARTICLE_COUNT" | bc -l 2>/dev/null || echo "N/A")%" >> $GITHUB_STEP_SUMMARY
        fi

        # Check latest blog post
        if ls hugo/content/posts/*-daily-summary.md 1> /dev/null 2>&1; then
          LATEST_POST=$(ls -t hugo/content/posts/*-daily-summary.md | head -1)
          if [ -f "$LATEST_POST" ]; then
            WORD_COUNT=$(wc -w < "$LATEST_POST" 2>/dev/null || echo "0")
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "### ğŸ“ Latest Blog Post:" >> $GITHUB_STEP_SUMMARY
            echo "- **File:** $(basename $LATEST_POST)" >> $GITHUB_STEP_SUMMARY
            echo "- **Word Count:** $WORD_COUNT words" >> $GITHUB_STEP_SUMMARY
          fi
        fi

        if [ "${{ steps.check-content.outputs.has-changes }}" = "true" ]; then
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "ğŸš€ **Next Step:** Hugo build will be triggered automatically" >> $GITHUB_STEP_SUMMARY
        fi
